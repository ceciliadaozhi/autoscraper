{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# 指定要清除的目录\noutput_dir = '/kaggle/working/'\n\n# 如果目录存在,则删除目录及其中的所有文件\nif os.path.exists(output_dir):\n    shutil.rmtree(output_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir /kaggle/working/models","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:34:27.358282Z","iopub.execute_input":"2024-04-06T12:34:27.358661Z","iopub.status.idle":"2024-04-06T12:34:28.326082Z","shell.execute_reply.started":"2024-04-06T12:34:27.358627Z","shell.execute_reply":"2024-04-06T12:34:28.324477Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# cd / \n# 回到根目录","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:34:03.248662Z","iopub.execute_input":"2024-04-06T12:34:03.249040Z","iopub.status.idle":"2024-04-06T12:34:03.255154Z","shell.execute_reply.started":"2024-04-06T12:34:03.248999Z","shell.execute_reply":"2024-04-06T12:34:03.254230Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/\n","output_type":"stream"}]},{"cell_type":"code","source":"# pwd\n# 查看当前目录","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:34:05.041769Z","iopub.execute_input":"2024-04-06T12:34:05.042127Z","iopub.status.idle":"2024-04-06T12:34:05.049346Z","shell.execute_reply.started":"2024-04-06T12:34:05.042099Z","shell.execute_reply":"2024-04-06T12:34:05.048447Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'/'"},"metadata":{}}]},{"cell_type":"code","source":"!git clone https://github.com/ceciliadaozhi/emergent_in_context_learning\n# %cd emergent_in_context_learning","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:35:33.657753Z","iopub.execute_input":"2024-04-06T12:35:33.658170Z","iopub.status.idle":"2024-04-06T12:35:34.603631Z","shell.execute_reply.started":"2024-04-06T12:35:33.658135Z","shell.execute_reply":"2024-04-06T12:35:34.602685Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"fatal: destination path 'emergent_in_context_learning' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 -m venv eicl_venv\n!source eicl_venv/bin/activate\n!pip install --upgrade pip\n!pip install -r emergent_in_context_learning/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:38:00.381914Z","iopub.execute_input":"2024-04-06T11:38:00.382872Z","iopub.status.idle":"2024-04-06T11:40:27.839949Z","shell.execute_reply.started":"2024-04-06T11:38:00.382834Z","shell.execute_reply":"2024-04-06T11:40:27.838800Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\nCollecting absl-py==1.2.0 (from -r emergent_in_context_learning/requirements.txt (line 1))\n  Downloading absl_py-1.2.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting dill==0.3.5.1 (from -r emergent_in_context_learning/requirements.txt (line 2))\n  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting dm-haiku==0.0.7 (from -r emergent_in_context_learning/requirements.txt (line 3))\n  Downloading dm_haiku-0.0.7-py3-none-any.whl.metadata (18 kB)\nCollecting jaxline==0.0.5 (from -r emergent_in_context_learning/requirements.txt (line 4))\n  Downloading jaxline-0.0.5.tar.gz (32 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ml_collections==0.1.1 (from -r emergent_in_context_learning/requirements.txt (line 5))\n  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting numpy==1.23.2 (from -r emergent_in_context_learning/requirements.txt (line 6))\n  Downloading numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nCollecting optax==0.1.3 (from -r emergent_in_context_learning/requirements.txt (line 7))\n  Downloading optax-0.1.3-py3-none-any.whl.metadata (12 kB)\nCollecting tensorflow==2.9.1 (from -r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting tensorflow_datasets==4.6.0 (from -r emergent_in_context_learning/requirements.txt (line 9))\n  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting jmp>=0.0.2 (from dm-haiku==0.0.7->-r emergent_in_context_learning/requirements.txt (line 3))\n  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.7->-r emergent_in_context_learning/requirements.txt (line 3)) (0.9.0)\nRequirement already satisfied: chex>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.1.85)\nRequirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (1.14.1)\nRequirement already satisfied: typing_extensions>=3.7 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (4.9.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5)) (6.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5)) (1.16.0)\nCollecting contextlib2 (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5))\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: jax>=0.1.55 in /opt/conda/lib/python3.10/site-packages (from optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.4.23)\nRequirement already satisfied: jaxlib>=0.1.37 in /opt/conda/lib/python3.10/site-packages (from optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.4.23.dev20240116)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.6.3)\nCollecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.10.0)\nCollecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (21.3)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (69.0.3)\nCollecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.35.0)\nCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.4.0)\nRequirement already satisfied: etils[epath] in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.6.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2.31.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (4.66.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.42.0)\nINFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\nCollecting chex>=0.0.2 (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4))\n  Downloading chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.84-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.83-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.82-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.81-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from chex>=0.0.2->jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.1.8)\n  Downloading chex-0.1.7-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chex>=0.0.2->jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.12.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.2.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (1.11.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2024.2.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.26.1)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.5.2)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.0.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2024.3.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (6.1.1)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.17.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.62.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.2.2)\nDownloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dm_haiku-0.0.7-py3-none-any.whl (342 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.4/342.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading optax-0.1.3-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chex-0.1.7-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\nDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: jaxline, ml_collections\n  Building wheel for jaxline (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jaxline: filename=jaxline-0.0.5-py3-none-any.whl size=33134 sha256=f8eeb15460539ea8e99f8166628be3471e854916c79466b54b096521eafbb47b\n  Stored in directory: /root/.cache/pip/wheels/df/59/6b/d4d1e0bcba957ab4e84e80d1f8dcf528d5074a5561b6d13e00\n  Building wheel for ml_collections (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94507 sha256=0cff13dc6c5a479582d4cb61842bd799636982a151c00b2212f840f83166f8c1\n  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\nSuccessfully built jaxline ml_collections\nInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, gast, dill, contextlib2, absl-py, ml_collections, keras-preprocessing, jmp, google-auth-oauthlib, dm-haiku, tensorflow_datasets, tensorboard, chex, tensorflow, optax, jaxline\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.5.26\n    Uninstalling flatbuffers-23.5.26:\n      Successfully uninstalled flatbuffers-23.5.26\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorflow_datasets\n    Found existing installation: tensorflow-datasets 4.9.4\n    Uninstalling tensorflow-datasets-4.9.4:\n      Successfully uninstalled tensorflow-datasets-4.9.4\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: chex\n    Found existing installation: chex 0.1.85\n    Uninstalling chex-0.1.85:\n      Successfully uninstalled chex-0.1.85\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n  Attempting uninstall: optax\n    Found existing installation: optax 0.2.1\n    Uninstalling optax-0.2.1:\n      Successfully uninstalled optax-0.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nalbumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.23.2 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\nfeaturetools 1.30.0 requires numpy>=1.25.0, but you have numpy 1.23.2 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.3.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nmultiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.5.1 which is incompatible.\nonnx 1.15.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.5.1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.2 which is incompatible.\npylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nrmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.9.1 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.9.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.1 which is incompatible.\ntensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.9.1 which is incompatible.\nwoodwork 0.29.0 requires numpy>=1.25.0, but you have numpy 1.23.2 which is incompatible.\nxarray 2024.2.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed absl-py-1.2.0 chex-0.1.7 contextlib2-21.6.0 dill-0.3.5.1 dm-haiku-0.0.7 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 jaxline-0.0.5 jmp-0.0.4 keras-2.9.0 keras-preprocessing-1.1.2 ml_collections-0.1.1 numpy-1.23.2 optax-0.1.3 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow_datasets-4.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall -y jax\n!pip install jax==0.4.13\n\n!pip uninstall -y jaxlib\n!pip install jaxlib==0.4.13\n\n!pip uninstall -y dm-haiku\n!pip install dm-haiku==0.0.9","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:41:45.778114Z","iopub.execute_input":"2024-04-06T11:41:45.778869Z","iopub.status.idle":"2024-04-06T11:42:37.519442Z","shell.execute_reply.started":"2024-04-06T11:41:45.778822Z","shell.execute_reply":"2024-04-06T11:42:37.518344Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found existing installation: jax 0.4.23\nUninstalling jax-0.4.23:\n  Successfully uninstalled jax-0.4.23\nCollecting jax==0.4.13\n  Downloading jax-0.4.13.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (0.2.0)\nRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (1.23.2)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (3.3.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (1.11.4)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518704 sha256=d4b533104fea59dcfe5c452113ed9d10db7110e652b337ac3d045c1baf540846\n  Stored in directory: /root/.cache/pip/wheels/f3/7a/25/f297f69029b5e4064e4736a0c4b3996a44cc27781c120bcb99\nSuccessfully built jax\nInstalling collected packages: jax\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflax 0.8.2 requires jax>=0.4.19, but you have jax 0.4.13 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed jax-0.4.13\nFound existing installation: jaxlib 0.4.23.dev20240116\nUninstalling jaxlib-0.4.23.dev20240116:\n  Successfully uninstalled jaxlib-0.4.23.dev20240116\nCollecting jaxlib==0.4.13\n  Downloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (1.11.4)\nRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (1.23.2)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (0.2.0)\nDownloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl (71.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hInstalling collected packages: jaxlib\nSuccessfully installed jaxlib-0.4.13\n","output_type":"stream"}]},{"cell_type":"code","source":"import jax  \nprint(jax.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T06:44:40.254941Z","iopub.execute_input":"2024-04-06T06:44:40.255351Z","iopub.status.idle":"2024-04-06T06:44:40.261224Z","shell.execute_reply.started":"2024-04-06T06:44:40.255318Z","shell.execute_reply":"2024-04-06T06:44:40.260110Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"0.4.25\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH_TO_CONFIG = 'emergent_in_context_learning/experiment/configs/images_all_exemplars.py'","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:44:48.877272Z","iopub.execute_input":"2024-04-06T11:44:48.877650Z","iopub.status.idle":"2024-04-06T11:44:48.882643Z","shell.execute_reply.started":"2024-04-06T11:44:48.877621Z","shell.execute_reply":"2024-04-06T11:44:48.881628Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!python -m emergent_in_context_learning.experiment.experiment --config $PATH_TO_CONFIG --jaxline_mode train --logtostderr\n# (save checkpoints using Ctrl+C)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:35:52.308981Z","iopub.execute_input":"2024-04-06T12:35:52.309368Z","iopub.status.idle":"2024-04-06T12:52:53.920680Z","shell.execute_reply.started":"2024-04-06T12:35:52.309336Z","shell.execute_reply":"2024-04-06T12:52:53.919561Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"I0406 12:35:57.702373 132745063814976 train.py:73] Training with config:\nbest_model_eval_metric: ''\nbest_model_eval_metric_higher_is_better: true\ncheckpoint_dir: /kaggle/working\ncheckpoint_interval_type: null\neval_initial_weights: false\neval_modes: !!python/tuple\n- eval_no_support_zipfian\n- eval_fewshot_zipfian\n- eval_fewshot_holdout\neval_specific_checkpoint_dir: ''\nexperiment_kwargs:\n  config:\n    data:\n      example_type: omniglot\n      generator_config:\n        n_common_classes: 10\n        n_holdout_classes: 10\n        n_rare_classes: 1603\n        noise_scale: 0.0\n        preserve_ordering_every_n: null\n        use_zipf_for_common_rare: false\n        zipf_exponent: 0.0\n      omniglot_config:\n        augment_images: false\n        exemplars: all\n        omniglot_split: all\n      seq_config:\n        bursty_shots: 3\n        fs_shots: 4\n        grouped: false\n        labeling_common: ordered\n        labeling_rare: ordered\n        non_bursty_type: zipfian\n        p_bursty: 0.9\n        p_bursty_common: 0.0\n        p_bursty_zipfian: 1.0\n        p_fewshot: 0.1\n        randomly_generate_rare: false\n        seq_len: 9\n        ways: 2\n      symbolic_config:\n        dataset_size: 1000\n      train_seqs: bursty\n    embedding:\n      concatenate_labels: false\n      emb_dim: 64\n      example_dropout_prob: 0.0\n      example_encoding: resnet\n      flatten_superpixels: false\n      num_classes: null\n      positional_dropout_prob: 0.0\n      use_positional_encodings: true\n    evaluation:\n      batch_size: 1\n    optimizer:\n      clip_level: 0.25\n      kwargs: {}\n      max_lr: 0.0003\n      name: adam\n      warmup_steps: 4000\n    preproc:\n      downsample: false\n    rnn:\n      dropout_prob: 0.0\n      hidden_size: 64\n      num_classes: null\n      num_layers: 12\n    seq_model: transformer\n    training:\n      batch_size: 32\n      learning_rate: 0.0001\n      w_interim_predictions: 0.0\n    transformer:\n      dropout_prob: 0.0\n      num_classes: null\n      num_heads: 8\n      num_layers: 12\ninterval_type: secs\nlog_all_train_data: false\nlog_tensors_interval: 60\nlog_train_data_interval: 60.0\nlogging_interval_type: null\nmax_checkpoints_to_keep: 5\none_off_evaluate: false\nrandom_mode_eval: same_host_same_device\nrandom_mode_train: unique_host_unique_device\nrandom_seed: 42\nrestore_path: ''\nsave_checkpoint_interval: 300\ntrain_checkpoint_all_hosts: false\ntraining_steps: 500000\n\n/opt/conda/lib/python3.10/site-packages/jax/_src/xla_bridge.py:817: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n  warnings.warn(\nI0406 12:35:57.721870 132745063814976 xla_bridge.py:603] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nI0406 12:35:57.722065 132745063814976 xla_bridge.py:603] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nI0406 12:35:57.722763 132745063814976 xla_bridge.py:603] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\nW0406 12:35:57.722952 132745063814976 xla_bridge.py:617] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\nI0406 12:35:57.750071 132745063814976 utils.py:299] [jaxline] experiment init starting...\nI0406 12:35:57.900932 132745063814976 dataset_info.py:580] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: omniglot/3.0.0\nI0406 12:35:58.381667 132745063814976 dataset_info.py:491] Load dataset info from /tmp/tmpfqjyqhuhtfds\nI0406 12:35:58.389147 132745063814976 dataset_info.py:550] Field info.description from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.389375 132745063814976 dataset_info.py:550] Field info.release_notes from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.389525 132745063814976 dataset_info.py:550] Field info.citation from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.389700 132745063814976 dataset_info.py:550] Field info.splits from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.389815 132745063814976 dataset_info.py:550] Field info.supervised_keys from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.389930 132745063814976 dataset_info.py:550] Field info.module_name from disk and from code do not match. Keeping the one from code.\nI0406 12:35:58.390235 132745063814976 dataset_builder.py:437] Generating dataset omniglot (~/tensorflow_datasets/omniglot/3.0.0)\n\u001b[1mDownloading and preparing dataset 17.95 MiB (download: 17.95 MiB, generated: Unknown size, total: 17.95 MiB) to ~/tensorflow_datasets/omniglot/3.0.0...\u001b[0m\nDl Completed...: 0 url [00:00, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0406 12:35:58.672849 132745063814976 download_manager.py:342] Skipping download of https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip: File cached in /root/tensorflow_datasets/downloads/brend_omnig_raw_maste_pytho_image_evaluH2Go8zZnhbBX_BF9kijnihbj2XbIlTsqEPzHTPBgnO4.zip\nDl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 1/1 [00:00<00:00, 495.78 url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 1/1 [00:00<00:00, 443.98 url/s]\nDl Size...:   0%|                                 | 0/6462886 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 1/1 [00:00<00:00, 391.00 url/s]\nDl Size...: 100%|███████████| 6462886/6462886 [00:00<00:00, 2684955289.36 MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0406 12:35:58.674624 132745063814976 download_manager.py:485] Reusing extraction of /root/tensorflow_datasets/downloads/brend_omnig_raw_maste_pytho_image_evaluH2Go8zZnhbBX_BF9kijnihbj2XbIlTsqEPzHTPBgnO4.zip at /root/tensorflow_datasets/downloads/extracted/ZIP.brend_omnig_raw_maste_pytho_image_evaluH2Go8zZnhbBX_BF9kijnihbj2XbIlTsqEPzHTPBgnO4.zip.\nI0406 12:35:58.675232 132745063814976 download_manager.py:342] Skipping download of https://github.com/brendenlake/omniglot/raw/master/python/images_background_small1.zip: File cached in /root/tensorflow_datasets/downloads/bren_omni_raw_mast_pyth_imag_back_smal8464D4ASdKwrTf9bJCiQFr-rpKfVu1De6_JxBK1suKQ.zip\nDl Completed...:  50%|████████████▌            | 1/2 [00:00<00:00, 247.92 url/s]\nDl Size...: 100%|███████████| 6462886/6462886 [00:00<00:00, 1666398758.30 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 2/2 [00:00<00:00, 455.70 url/s]\nDl Size...: 100%|███████████| 6462886/6462886 [00:00<00:00, 1534781372.51 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 2/2 [00:00<00:00, 424.78 url/s]\nDl Size...:  83%|█████████▏ | 6462886/7781908 [00:00<00:00, 1426175019.80 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 2/2 [00:00<00:00, 400.93 url/s]\nDl Size...: 100%|███████████| 7781908/7781908 [00:00<00:00, 1627021975.58 MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0406 12:35:58.676848 132745063814976 download_manager.py:485] Reusing extraction of /root/tensorflow_datasets/downloads/bren_omni_raw_mast_pyth_imag_back_smal8464D4ASdKwrTf9bJCiQFr-rpKfVu1De6_JxBK1suKQ.zip at /root/tensorflow_datasets/downloads/extracted/ZIP.bren_omni_raw_mast_pyth_imag_back_smal8464D4ASdKwrTf9bJCiQFr-rpKfVu1De6_JxBK1suKQ.zip.\nI0406 12:35:58.677602 132745063814976 download_manager.py:342] Skipping download of https://github.com/brendenlake/omniglot/raw/master/python/images_background_small2.zip: File cached in /root/tensorflow_datasets/downloads/bren_omni_raw_mast_pyth_imag_back_smalPMqkB1Fah3jl0IYYda84sX5BjzAa1bs7Wmtl2QGkHH8.zip\nDl Completed...:  67%|████████████████▋        | 2/3 [00:00<00:00, 310.69 url/s]\nDl Size...: 100%|███████████| 7781908/7781908 [00:00<00:00, 1221773829.39 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 3/3 [00:00<00:00, 431.17 url/s]\nDl Size...: 100%|███████████| 7781908/7781908 [00:00<00:00, 1140649584.21 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 3/3 [00:00<00:00, 406.88 url/s]\nDl Size...:  83%|█████████▏ | 7781908/9362825 [00:00<00:00, 1076968616.23 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 3/3 [00:00<00:00, 382.84 url/s]\nDl Size...: 100%|███████████| 9362825/9362825 [00:00<00:00, 1220908886.95 MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0406 12:35:58.679827 132745063814976 download_manager.py:485] Reusing extraction of /root/tensorflow_datasets/downloads/bren_omni_raw_mast_pyth_imag_back_smalPMqkB1Fah3jl0IYYda84sX5BjzAa1bs7Wmtl2QGkHH8.zip at /root/tensorflow_datasets/downloads/extracted/ZIP.bren_omni_raw_mast_pyth_imag_back_smalPMqkB1Fah3jl0IYYda84sX5BjzAa1bs7Wmtl2QGkHH8.zip.\nI0406 12:35:58.680389 132745063814976 download_manager.py:342] Skipping download of https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip: File cached in /root/tensorflow_datasets/downloads/brend_omnig_raw_maste_pytho_image_backgrUGrZ5yLXZCyce9GvmmHzIEhF3SmlcKdzFNnsrJu5kA.zip\nDl Completed...:  75%|██████████████████▊      | 3/4 [00:00<00:00, 326.43 url/s]\nDl Size...: 100%|███████████| 9362825/9362825 [00:00<00:00, 1036079844.57 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 4/4 [00:00<00:00, 418.98 url/s]\nDl Size...: 100%|████████████| 9362825/9362825 [00:00<00:00, 998462646.48 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 4/4 [00:00<00:00, 404.74 url/s]\nDl Size...:  50%|█████▍     | 9362825/18827037 [00:00<00:00, 967469004.18 MiB/s]\u001b[A\n\nDl Completed...: 100%|█████████████████████████| 4/4 [00:00<00:00, 394.88 url/s]\nDl Size...: 100%|█████████| 18827037/18827037 [00:00<00:00, 1896587486.72 MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0406 12:35:58.681972 132745063814976 download_manager.py:485] Reusing extraction of /root/tensorflow_datasets/downloads/brend_omnig_raw_maste_pytho_image_backgrUGrZ5yLXZCyce9GvmmHzIEhF3SmlcKdzFNnsrJu5kA.zip at /root/tensorflow_datasets/downloads/extracted/ZIP.brend_omnig_raw_maste_pytho_image_backgrUGrZ5yLXZCyce9GvmmHzIEhF3SmlcKdzFNnsrJu5kA.zip.\nExtraction completed...: 0 file [00:00, ? file/s]\nDl Size...: 100%|█████████| 18827037/18827037 [00:00<00:00, 1702373918.80 MiB/s]\nDl Completed...: 100%|█████████████████████████| 4/4 [00:00<00:00, 347.35 url/s]\nGenerating splits...:   0%|                          | 0/4 [00:00<?, ? splits/s]\nGenerating train examples...:   0%|            | 0/19280 [00:00<?, ? examples/s]\u001b[A\nGenerating train examples...:   2%| | 465/19280 [00:00<00:04, 4645.62 examples/s\u001b[A\nGenerating train examples...:   5%| | 941/19280 [00:00<00:03, 4709.48 examples/s\u001b[A\nGenerating train examples...:   7%| | 1420/19280 [00:00<00:03, 4745.66 examples/\u001b[A\nGenerating train examples...:  10%| | 1906/19280 [00:00<00:03, 4787.96 examples/\u001b[A\nGenerating train examples...:  12%| | 2385/19280 [00:00<00:03, 4781.30 examples/\u001b[A\nGenerating train examples...:  15%|▏| 2864/19280 [00:00<00:03, 4772.44 examples/\u001b[A\nGenerating train examples...:  17%|▏| 3342/19280 [00:00<00:03, 4772.99 examples/\u001b[A\nGenerating train examples...:  20%|▏| 3834/19280 [00:00<00:03, 4817.61 examples/\u001b[A\nGenerating train examples...:  22%|▏| 4321/19280 [00:00<00:03, 4832.67 examples/\u001b[A\nGenerating train examples...:  25%|▏| 4808/19280 [00:01<00:02, 4843.24 examples/\u001b[A\nGenerating train examples...:  27%|▎| 5293/19280 [00:01<00:02, 4834.64 examples/\u001b[A\nGenerating train examples...:  30%|▎| 5781/19280 [00:01<00:02, 4845.82 examples/\u001b[A\nGenerating train examples...:  33%|▎| 6272/19280 [00:01<00:02, 4863.39 examples/\u001b[A\nGenerating train examples...:  35%|▎| 6765/19280 [00:01<00:02, 4882.12 examples/\u001b[A\nGenerating train examples...:  38%|▍| 7263/19280 [00:01<00:02, 4909.66 examples/\u001b[A\nGenerating train examples...:  40%|▍| 7754/19280 [00:01<00:02, 4895.99 examples/\u001b[A\nGenerating train examples...:  43%|▍| 8250/19280 [00:01<00:02, 4913.82 examples/\u001b[A\nGenerating train examples...:  45%|▍| 8742/19280 [00:01<00:02, 4901.31 examples/\u001b[A\nGenerating train examples...:  48%|▍| 9233/19280 [00:01<00:02, 4530.52 examples/\u001b[A\nGenerating train examples...:  50%|▌| 9692/19280 [00:02<00:02, 4544.94 examples/\u001b[A\nGenerating train examples...:  53%|▌| 10151/19280 [00:02<00:02, 4465.52 examples\u001b[A\nGenerating train examples...:  55%|▌| 10601/19280 [00:02<00:01, 4418.11 examples\u001b[A\nGenerating train examples...:  57%|▌| 11048/19280 [00:02<00:01, 4430.76 examples\u001b[A\nGenerating train examples...:  60%|▌| 11512/19280 [00:02<00:01, 4490.55 examples\u001b[A\nGenerating train examples...:  62%|▌| 11984/19280 [00:02<00:01, 4555.91 examples\u001b[A\nGenerating train examples...:  65%|▋| 12456/19280 [00:02<00:01, 4603.68 examples\u001b[A\nGenerating train examples...:  67%|▋| 12918/19280 [00:02<00:01, 4542.28 examples\u001b[A\nGenerating train examples...:  69%|▋| 13373/19280 [00:02<00:01, 4498.31 examples\u001b[A\nGenerating train examples...:  72%|▋| 13853/19280 [00:02<00:01, 4586.40 examples\u001b[A\nGenerating train examples...:  74%|▋| 14344/19280 [00:03<00:01, 4681.28 examples\u001b[A\nGenerating train examples...:  77%|▊| 14820/19280 [00:03<00:00, 4702.10 examples\u001b[A\nGenerating train examples...:  79%|▊| 15315/19280 [00:03<00:00, 4775.09 examples\u001b[A\nGenerating train examples...:  82%|▊| 15804/19280 [00:03<00:00, 4808.59 examples\u001b[A\nGenerating train examples...:  85%|▊| 16295/19280 [00:03<00:00, 4838.59 examples\u001b[A\nGenerating train examples...:  87%|▊| 16782/19280 [00:03<00:00, 4844.14 examples\u001b[A\nGenerating train examples...:  90%|▉| 17272/19280 [00:03<00:00, 4858.58 examples\u001b[A\nGenerating train examples...:  92%|▉| 17768/19280 [00:03<00:00, 4888.08 examples\u001b[A\nGenerating train examples...:  95%|▉| 18257/19280 [00:03<00:00, 4866.44 examples\u001b[A\nGenerating train examples...:  97%|▉| 18744/19280 [00:03<00:00, 4828.32 examples\u001b[A\nGenerating train examples...: 100%|▉| 19234/19280 [00:04<00:00, 4848.45 examples\u001b[A\n                                                                                \u001b[A\nShuffling ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-train.t\u001b[A\n                                                                                \u001b[AI0406 12:36:03.093211 132745063814976 writer.py:333] Done writing ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-train.tfrecord*. Number of examples: 19280 (shards: [19280])\nGenerating splits...:  25%|████▌             | 1/4 [00:04<00:12,  4.15s/ splits]\nGenerating test examples...:   0%|             | 0/13180 [00:00<?, ? examples/s]\u001b[A\nGenerating test examples...:   4%| | 485/13180 [00:00<00:02, 4845.03 examples/s]\u001b[A\nGenerating test examples...:   7%| | 975/13180 [00:00<00:02, 4875.93 examples/s]\u001b[A\nGenerating test examples...:  11%| | 1463/13180 [00:00<00:02, 4823.70 examples/s\u001b[A\nGenerating test examples...:  15%|▏| 1950/13180 [00:00<00:02, 4841.55 examples/s\u001b[A\nGenerating test examples...:  18%|▏| 2435/13180 [00:00<00:02, 4788.06 examples/s\u001b[A\nGenerating test examples...:  22%|▏| 2914/13180 [00:00<00:02, 4782.29 examples/s\u001b[A\nGenerating test examples...:  26%|▎| 3398/13180 [00:00<00:02, 4800.80 examples/s\u001b[A\nGenerating test examples...:  29%|▎| 3887/13180 [00:00<00:01, 4828.53 examples/s\u001b[A\nGenerating test examples...:  33%|▎| 4383/13180 [00:00<00:01, 4869.34 examples/s\u001b[A\nGenerating test examples...:  37%|▎| 4870/13180 [00:01<00:01, 4839.84 examples/s\u001b[A\nGenerating test examples...:  41%|▍| 5358/13180 [00:01<00:01, 4851.68 examples/s\u001b[A\nGenerating test examples...:  44%|▍| 5852/13180 [00:01<00:01, 4877.41 examples/s\u001b[A\nGenerating test examples...:  48%|▍| 6340/13180 [00:01<00:01, 4870.39 examples/s\u001b[A\nGenerating test examples...:  52%|▌| 6828/13180 [00:01<00:01, 4873.11 examples/s\u001b[A\nGenerating test examples...:  56%|▌| 7316/13180 [00:01<00:01, 4824.77 examples/s\u001b[A\nGenerating test examples...:  59%|▌| 7799/13180 [00:01<00:01, 4824.84 examples/s\u001b[A\nGenerating test examples...:  63%|▋| 8282/13180 [00:01<00:01, 4826.21 examples/s\u001b[A\nGenerating test examples...:  67%|▋| 8774/13180 [00:01<00:00, 4851.81 examples/s\u001b[A\nGenerating test examples...:  70%|▋| 9262/13180 [00:01<00:00, 4859.53 examples/s\u001b[A\nGenerating test examples...:  74%|▋| 9748/13180 [00:02<00:00, 4845.98 examples/s\u001b[A\nGenerating test examples...:  78%|▊| 10233/13180 [00:02<00:00, 4840.67 examples/\u001b[A\nGenerating test examples...:  81%|▊| 10721/13180 [00:02<00:00, 4849.20 examples/\u001b[A\nGenerating test examples...:  85%|▊| 11207/13180 [00:02<00:00, 4852.36 examples/\u001b[A\nGenerating test examples...:  89%|▉| 11693/13180 [00:02<00:00, 4834.61 examples/\u001b[A\nGenerating test examples...:  92%|▉| 12177/13180 [00:02<00:00, 4801.48 examples/\u001b[A\nGenerating test examples...:  96%|▉| 12664/13180 [00:02<00:00, 4821.68 examples/\u001b[A\nGenerating test examples...: 100%|▉| 13151/13180 [00:02<00:00, 4835.12 examples/\u001b[A\n                                                                                \u001b[A\nShuffling ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-test.tf\u001b[A\n                                                                                \u001b[AI0406 12:36:05.878624 132745063814976 writer.py:333] Done writing ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-test.tfrecord*. Number of examples: 13180 (shards: [13180])\nGenerating splits...:  50%|█████████         | 2/4 [00:06<00:06,  3.35s/ splits]\nGenerating small1 examples...:   0%|            | 0/2720 [00:00<?, ? examples/s]\u001b[A\nGenerating small1 examples...:  18%|▏| 486/2720 [00:00<00:00, 4852.91 examples/s\u001b[A\nGenerating small1 examples...:  36%|▎| 972/2720 [00:00<00:00, 4802.28 examples/s\u001b[A\nGenerating small1 examples...:  54%|▌| 1456/2720 [00:00<00:00, 4818.57 examples/\u001b[A\nGenerating small1 examples...:  71%|▋| 1940/2720 [00:00<00:00, 4826.11 examples/\u001b[A\nGenerating small1 examples...:  89%|▉| 2423/2720 [00:00<00:00, 4824.33 examples/\u001b[A\n                                                                                \u001b[A\nShuffling ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-small1.\u001b[A\n                                                                                \u001b[AI0406 12:36:06.463978 132745063814976 writer.py:333] Done writing ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-small1.tfrecord*. Number of examples: 2720 (shards: [2720])\nGenerating splits...:  75%|█████████████▌    | 3/4 [00:07<00:02,  2.09s/ splits]\nGenerating small2 examples...:   0%|            | 0/3120 [00:00<?, ? examples/s]\u001b[A\nGenerating small2 examples...:  16%|▏| 489/3120 [00:00<00:00, 4883.38 examples/s\u001b[A\nGenerating small2 examples...:  31%|▎| 978/3120 [00:00<00:00, 4797.19 examples/s\u001b[A\nGenerating small2 examples...:  47%|▍| 1458/3120 [00:00<00:00, 4792.25 examples/\u001b[A\nGenerating small2 examples...:  62%|▌| 1938/3120 [00:00<00:00, 4789.36 examples/\u001b[A\nGenerating small2 examples...:  78%|▊| 2421/3120 [00:00<00:00, 4801.21 examples/\u001b[A\nGenerating small2 examples...:  93%|▉| 2902/3120 [00:00<00:00, 4785.87 examples/\u001b[A\n                                                                                \u001b[A\nShuffling ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-small2.\u001b[A\n                                                                                \u001b[AI0406 12:36:07.135637 132745063814976 writer.py:333] Done writing ~/tensorflow_datasets/omniglot/3.0.0.incompleteHQV2N6/omniglot-small2.tfrecord*. Number of examples: 3120 (shards: [3120])\n\u001b[1mDataset omniglot downloaded and prepared to ~/tensorflow_datasets/omniglot/3.0.0. Subsequent calls will reuse this data.\u001b[0m\nI0406 12:36:07.139966 132745063814976 logging_logger.py:44] Constructing tf.data.Dataset omniglot for split train, from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 12:36:13.852027 132745063814976 dataset_info.py:491] Load dataset info from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 12:36:13.858704 132745063814976 dataset_builder.py:383] Reusing dataset omniglot (~/tensorflow_datasets/omniglot/3.0.0)\nI0406 12:36:13.858891 132745063814976 logging_logger.py:44] Constructing tf.data.Dataset omniglot for split test, from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 12:36:19.071349 132745063814976 data_generators.py:191] Loaded 1623 classes of type \"omniglot\"\nI0406 12:36:19.072753 132745063814976 data_generators.py:235] 1603 rare classes: [318, 1589, 543, 304, 851, 853, 941, 1346, 148, 138, 1259, 472, 680, 96, 1245, 975, 924, 190, 1037, 149] ...\nI0406 12:36:19.073211 132745063814976 data_generators.py:237] 10 common classes: [580, 243, 1316, 493, 171, 1006, 524, 864, 387, 170] ...\nI0406 12:36:19.073361 132745063814976 data_generators.py:239] 10 holdout classes: [198, 184, 1152, 480, 336, 583, 614, 575, 168, 585] ...\nI0406 12:36:19.073487 132745063814976 data_generators.py:241] Zipf exponent: 0\nI0406 12:36:19.073591 132745063814976 data_generators.py:242] Use Zipf for common/rare: False\nI0406 12:36:19.074077 132745063814976 data_generators.py:243] Noise scale: 0\nI0406 12:37:22.217171 132745063814976 utils.py:306] [jaxline] experiment init finished.\nI0406 12:37:22.236027 132745063814976 utils.py:299] [jaxline] training loop starting...\nI0406 12:39:39.908424 132739235829504 train.py:38] global_step: 1, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0.03125, dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0.03125, dtype=float32), 'label': array(1004, dtype=int32), 'loss': array(7.732368, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.732368, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.007276321736563142}\nI0406 12:40:41.517376 132739235829504 train.py:38] global_step: 14, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(1411, dtype=int32), 'loss': array(7.8667097, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.8667097, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.21014268761172078}\nI0406 12:41:43.239506 132739235829504 train.py:38] global_step: 27, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(517, dtype=int32), 'loss': array(8.021102, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(8.021102, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.21062050525727413}\nI0406 12:42:26.031918 132745063814976 utils.py:578] Saved checkpoint latest with id 0.\nI0406 12:42:44.890471 132739235829504 train.py:38] global_step: 40, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(389, dtype=int32), 'loss': array(7.803514, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.803514, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.21086351648299548}\nI0406 12:43:46.830035 132739235829504 train.py:38] global_step: 53, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(359, dtype=int32), 'loss': array(8.168181, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(8.168181, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.2098822307371354}\nI0406 12:44:48.738712 132739235829504 train.py:38] global_step: 66, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(373, dtype=int32), 'loss': array(7.6707897, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.6707897, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.2099861532098772}\nI0406 12:45:50.397767 132739235829504 train.py:38] global_step: 79, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(207, dtype=int32), 'loss': array(7.9435883, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.9435883, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.21083678194160918}\nI0406 12:46:52.546887 132739235829504 train.py:38] global_step: 92, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(43, dtype=int32), 'loss': array(7.9040565, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.9040565, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.20918427422092928}\nI0406 12:47:30.810293 132745063814976 utils.py:578] Saved checkpoint latest with id 1.\nI0406 12:47:54.525477 132739235829504 train.py:38] global_step: 105, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(69, dtype=int32), 'loss': array(7.724188, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.724188, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.20974113933205854}\nI0406 12:48:56.672445 132739235829504 train.py:38] global_step: 118, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(1568, dtype=int32), 'loss': array(7.825829, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.825829, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.2091818867569845}\nI0406 12:49:58.681400 132739235829504 train.py:38] global_step: 131, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(1118, dtype=int32), 'loss': array(7.7437077, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.7437077, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.2096470405217873}\nI0406 12:51:01.048948 132739235829504 train.py:38] global_step: 144, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(598, dtype=int32), 'loss': array(7.760604, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.760604, dtype=float32), 'prediction': array(907, dtype=int32), 'steps_per_sec': 0.20847620426857985}\nI0406 12:52:03.477619 132739235829504 train.py:38] global_step: 157, {'accuracy_closed': array(0., dtype=float32), 'accuracy_interim': array(0., dtype=float32), 'accuracy_query': array(0., dtype=float32), 'from_common': array(0., dtype=float32), 'from_fewshot': array(0., dtype=float32), 'from_rare': array(1., dtype=float32), 'from_support': array(0., dtype=float32), 'from_support_common': array(0., dtype=float32), 'from_support_fewshot': array(0., dtype=float32), 'from_support_rare': array(0., dtype=float32), 'label': array(1005, dtype=int32), 'loss': array(7.718702, dtype=float32), 'loss_interim': array(0., dtype=float32), 'loss_query': array(7.718702, dtype=float32), 'prediction': array(210, dtype=int32), 'steps_per_sec': 0.20823907489188237}\nI0406 12:52:32.027768 132745063814976 utils.py:578] Saved checkpoint latest with id 2.\n^C\n","output_type":"stream"}]},{"cell_type":"code","source":"CKPT_DIR = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:10:19.497267Z","iopub.execute_input":"2024-04-06T11:10:19.498137Z","iopub.status.idle":"2024-04-06T11:10:19.504455Z","shell.execute_reply.started":"2024-04-06T11:10:19.498098Z","shell.execute_reply":"2024-04-06T11:10:19.503269Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"!python -m emergent_in_context_learning.experiment.experiment --config $PATH_TO_CONFIG $CKPT_DIR --jaxline_mode eval_fewshot_holdout","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:35:05.257782Z","iopub.execute_input":"2024-04-06T10:35:05.258206Z","iopub.status.idle":"2024-04-06T10:36:02.952331Z","shell.execute_reply.started":"2024-04-06T10:35:05.258178Z","shell.execute_reply":"2024-04-06T10:36:02.951128Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"I0406 10:35:11.462625 135442812516160 train.py:152] Evaluating with config:\nbest_model_eval_metric: ''\nbest_model_eval_metric_higher_is_better: true\ncheckpoint_dir: /tmp/jaxline/transformer_omniglot/\ncheckpoint_interval_type: null\neval_initial_weights: false\neval_modes: !!python/tuple\n- eval_no_support_zipfian\n- eval_fewshot_zipfian\n- eval_fewshot_holdout\neval_specific_checkpoint_dir: ''\nexperiment_kwargs:\n  config:\n    data:\n      example_type: omniglot\n      generator_config:\n        n_common_classes: 10\n        n_holdout_classes: 10\n        n_rare_classes: 1603\n        noise_scale: 0.0\n        preserve_ordering_every_n: null\n        use_zipf_for_common_rare: false\n        zipf_exponent: 0.0\n      omniglot_config:\n        augment_images: false\n        exemplars: all\n        omniglot_split: all\n      seq_config:\n        bursty_shots: 3\n        fs_shots: 4\n        grouped: false\n        labeling_common: ordered\n        labeling_rare: ordered\n        non_bursty_type: zipfian\n        p_bursty: 0.9\n        p_bursty_common: 0.0\n        p_bursty_zipfian: 1.0\n        p_fewshot: 0.1\n        randomly_generate_rare: false\n        seq_len: 9\n        ways: 2\n      symbolic_config:\n        dataset_size: 1000\n      train_seqs: bursty\n    embedding:\n      concatenate_labels: false\n      emb_dim: 64\n      example_dropout_prob: 0.0\n      example_encoding: resnet\n      flatten_superpixels: false\n      num_classes: null\n      positional_dropout_prob: 0.0\n      use_positional_encodings: true\n    evaluation:\n      batch_size: 1\n    optimizer:\n      clip_level: 0.25\n      kwargs: {}\n      max_lr: 0.0003\n      name: adam\n      warmup_steps: 4000\n    preproc:\n      downsample: false\n    rnn:\n      dropout_prob: 0.0\n      hidden_size: 64\n      num_classes: null\n      num_layers: 12\n    seq_model: transformer\n    training:\n      batch_size: 32\n      learning_rate: 0.0001\n      w_interim_predictions: 0.0\n    transformer:\n      dropout_prob: 0.0\n      num_classes: null\n      num_heads: 8\n      num_layers: 12\ninterval_type: secs\nlog_all_train_data: false\nlog_tensors_interval: 60\nlog_train_data_interval: 60.0\nlogging_interval_type: null\nmax_checkpoints_to_keep: 5\none_off_evaluate: false\nrandom_mode_eval: same_host_same_device\nrandom_mode_train: unique_host_unique_device\nrandom_seed: 42\nrestore_path: ''\nsave_checkpoint_interval: 300\ntrain_checkpoint_all_hosts: false\ntraining_steps: 500000\n\nI0406 10:35:11.490935 135442812516160 xla_bridge.py:603] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nI0406 10:35:11.491250 135442812516160 xla_bridge.py:603] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nI0406 10:35:11.492435 135442812516160 xla_bridge.py:603] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\nW0406 10:35:11.492685 135442812516160 xla_bridge.py:617] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\nI0406 10:35:11.524433 135442812516160 dataset_info.py:491] Load dataset info from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 10:35:11.532611 135442812516160 dataset_builder.py:383] Reusing dataset omniglot (~/tensorflow_datasets/omniglot/3.0.0)\nI0406 10:35:11.532936 135442812516160 logging_logger.py:44] Constructing tf.data.Dataset omniglot for split train, from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 10:35:19.652402 135442812516160 dataset_info.py:491] Load dataset info from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 10:35:19.660110 135442812516160 dataset_builder.py:383] Reusing dataset omniglot (~/tensorflow_datasets/omniglot/3.0.0)\nI0406 10:35:19.660405 135442812516160 logging_logger.py:44] Constructing tf.data.Dataset omniglot for split test, from ~/tensorflow_datasets/omniglot/3.0.0\nI0406 10:35:25.283032 135442812516160 data_generators.py:191] Loaded 1623 classes of type \"omniglot\"\nI0406 10:35:25.284756 135442812516160 data_generators.py:235] 1603 rare classes: [318, 1589, 543, 304, 851, 853, 941, 1346, 148, 138, 1259, 472, 680, 96, 1245, 975, 924, 190, 1037, 149] ...\nI0406 10:35:25.285020 135442812516160 data_generators.py:237] 10 common classes: [580, 243, 1316, 493, 171, 1006, 524, 864, 387, 170] ...\nI0406 10:35:25.285164 135442812516160 data_generators.py:239] 10 holdout classes: [198, 184, 1152, 480, 336, 583, 614, 575, 168, 585] ...\nI0406 10:35:25.285304 135442812516160 data_generators.py:241] Zipf exponent: 0\nI0406 10:35:25.285398 135442812516160 data_generators.py:242] Use Zipf for common/rare: False\nI0406 10:35:25.285842 135442812516160 data_generators.py:243] Noise scale: 0\nI0406 10:35:25.341746 135442812516160 train.py:216] Checkpoint None invalid or already evaluated, waiting.\nI0406 10:35:35.352737 135442812516160 train.py:216] Checkpoint None invalid or already evaluated, waiting.\nI0406 10:35:45.363335 135442812516160 train.py:216] Checkpoint None invalid or already evaluated, waiting.\nI0406 10:35:55.374050 135442812516160 train.py:216] Checkpoint None invalid or already evaluated, waiting.\n^C\nI0406 10:36:02.346024 135442812516160 experiment.py:695] Saving model.\nI0406 10:36:02.346390 135442812516160 experiment.py:699] Nothing to save in \"latest\"\nI0406 10:36:02.346540 135442812516160 experiment.py:674] Use `Ctrl+\\` to save and exit.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m emergent_in_context_learning.experiment.experiment --config $PATH_TO_CONFIG --logtostderr --config.one_off_evaluate --config.restore_path $CKPT_DIR --jaxline_mode eval_no_support_zipfian","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:40:28.018010Z","iopub.execute_input":"2024-04-06T10:40:28.019174Z","iopub.status.idle":"2024-04-06T10:40:35.278478Z","shell.execute_reply.started":"2024-04-06T10:40:28.019135Z","shell.execute_reply":"2024-04-06T10:40:35.277350Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 744, in <module>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 744, in <lambda>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 724, in main\n    _restore_state_to_in_memory_checkpointer(restore_path)\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 637, in _restore_state_to_in_memory_checkpointer\n    with open(python_state_path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/jaxline/transformer_omniglot/checkpoint.dill'\n","output_type":"stream"}]},{"cell_type":"code","source":"!echo $PATH_TO_CONFIG","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:36:20.755338Z","iopub.execute_input":"2024-04-06T10:36:20.755789Z","iopub.status.idle":"2024-04-06T10:36:21.858025Z","shell.execute_reply.started":"2024-04-06T10:36:20.755754Z","shell.execute_reply":"2024-04-06T10:36:21.856542Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"emergent_in_context_learning/experiment/configs/images_all_exemplars.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!echo $CKPT_DIR ","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:38:54.044349Z","iopub.execute_input":"2024-04-06T10:38:54.045014Z","iopub.status.idle":"2024-04-06T10:38:55.144600Z","shell.execute_reply.started":"2024-04-06T10:38:54.044983Z","shell.execute_reply":"2024-04-06T10:38:55.143146Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"/tmp/jaxline/transformer_omniglot/\n","output_type":"stream"}]},{"cell_type":"code","source":"ls $CKPT_DIR","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:05:29.380272Z","iopub.execute_input":"2024-04-06T11:05:29.380694Z","iopub.status.idle":"2024-04-06T11:05:30.476585Z","shell.execute_reply.started":"2024-04-06T11:05:29.380661Z","shell.execute_reply":"2024-04-06T11:05:30.474994Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34meval_fewshot_holdout\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"CKPT_DIR2 = '/tmp/jaxline/transformer_omniglot/train/events.out.tfevents.1712400921.ddfd5b442305.1029.0.v2'","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:06:13.894512Z","iopub.execute_input":"2024-04-06T11:06:13.894967Z","iopub.status.idle":"2024-04-06T11:06:13.901181Z","shell.execute_reply.started":"2024-04-06T11:06:13.894932Z","shell.execute_reply":"2024-04-06T11:06:13.899884Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"ls $CKPT_DIR2","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:06:15.366879Z","iopub.execute_input":"2024-04-06T11:06:15.367344Z","iopub.status.idle":"2024-04-06T11:06:16.468343Z","shell.execute_reply.started":"2024-04-06T11:06:15.367310Z","shell.execute_reply":"2024-04-06T11:06:16.466932Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"/tmp/jaxline/transformer_omniglot/train/events.out.tfevents.1712400921.ddfd5b442305.1029.0.v2\n","output_type":"stream"}]}]}