{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-04-07T11:10:06.142366Z","iopub.execute_input":"2024-04-07T11:10:06.142769Z","iopub.status.idle":"2024-04-07T11:10:07.118724Z","shell.execute_reply.started":"2024-04-07T11:10:06.142737Z","shell.execute_reply":"2024-04-07T11:10:07.117659Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ceciliadaozhi/emergent_in_context_learning","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:10:07.120740Z","iopub.execute_input":"2024-04-07T11:10:07.121285Z","iopub.status.idle":"2024-04-07T11:10:08.678795Z","shell.execute_reply.started":"2024-04-07T11:10:07.121246Z","shell.execute_reply":"2024-04-07T11:10:08.677748Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'emergent_in_context_learning'...\nremote: Enumerating objects: 74, done.\u001b[K\nremote: Counting objects: 100% (74/74), done.\u001b[K\nremote: Compressing objects: 100% (54/54), done.\u001b[K\nremote: Total 74 (delta 33), reused 51 (delta 19), pack-reused 0\u001b[K\nUnpacking objects: 100% (74/74), 49.93 KiB | 1.47 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 -m venv eicl_venv\n!source eicl_venv/bin/activate\n!pip install --upgrade pip\n!pip install -r emergent_in_context_learning/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:10:08.680303Z","iopub.execute_input":"2024-04-07T11:10:08.680630Z","iopub.status.idle":"2024-04-07T11:12:04.606496Z","shell.execute_reply.started":"2024-04-07T11:10:08.680601Z","shell.execute_reply":"2024-04-07T11:12:04.605220Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\nCollecting absl-py==1.2.0 (from -r emergent_in_context_learning/requirements.txt (line 1))\n  Downloading absl_py-1.2.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting dill==0.3.5.1 (from -r emergent_in_context_learning/requirements.txt (line 2))\n  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting dm-haiku==0.0.7 (from -r emergent_in_context_learning/requirements.txt (line 3))\n  Downloading dm_haiku-0.0.7-py3-none-any.whl.metadata (18 kB)\nCollecting jaxline==0.0.5 (from -r emergent_in_context_learning/requirements.txt (line 4))\n  Downloading jaxline-0.0.5.tar.gz (32 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ml_collections==0.1.1 (from -r emergent_in_context_learning/requirements.txt (line 5))\n  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting numpy==1.23.2 (from -r emergent_in_context_learning/requirements.txt (line 6))\n  Downloading numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nCollecting optax==0.1.3 (from -r emergent_in_context_learning/requirements.txt (line 7))\n  Downloading optax-0.1.3-py3-none-any.whl.metadata (12 kB)\nCollecting tensorflow==2.9.1 (from -r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting tensorflow_datasets==4.6.0 (from -r emergent_in_context_learning/requirements.txt (line 9))\n  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting jmp>=0.0.2 (from dm-haiku==0.0.7->-r emergent_in_context_learning/requirements.txt (line 3))\n  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.7->-r emergent_in_context_learning/requirements.txt (line 3)) (0.9.0)\nRequirement already satisfied: chex>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.1.85)\nRequirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (1.14.1)\nRequirement already satisfied: typing_extensions>=3.7 in /opt/conda/lib/python3.10/site-packages (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (4.9.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5)) (6.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5)) (1.16.0)\nCollecting contextlib2 (from ml_collections==0.1.1->-r emergent_in_context_learning/requirements.txt (line 5))\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: jax>=0.1.55 in /opt/conda/lib/python3.10/site-packages (from optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.4.23)\nRequirement already satisfied: jaxlib>=0.1.37 in /opt/conda/lib/python3.10/site-packages (from optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.4.23.dev20240116)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.6.3)\nCollecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.10.0)\nCollecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (21.3)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (69.0.3)\nCollecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.35.0)\nCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.4.0)\nRequirement already satisfied: etils[epath] in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.6.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2.31.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (4.66.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.42.0)\nINFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\nCollecting chex>=0.0.2 (from jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4))\n  Downloading chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.84-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.83-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.82-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.81-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: dm-tree>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from chex>=0.0.2->jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.1.8)\n  Downloading chex-0.1.7-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chex>=0.0.2->jaxline==0.0.5->-r emergent_in_context_learning/requirements.txt (line 4)) (0.12.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (0.2.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.1.55->optax==0.1.3->-r emergent_in_context_learning/requirements.txt (line 7)) (1.11.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2024.2.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.26.1)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.5.2)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8))\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.0.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (2024.3.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (6.1.1)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (3.17.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0->-r emergent_in_context_learning/requirements.txt (line 9)) (1.62.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r emergent_in_context_learning/requirements.txt (line 8)) (3.2.2)\nDownloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dm_haiku-0.0.7-py3-none-any.whl (342 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.4/342.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading optax-0.1.3-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading chex-0.1.7-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\nDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: jaxline, ml_collections\n  Building wheel for jaxline (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jaxline: filename=jaxline-0.0.5-py3-none-any.whl size=33134 sha256=1e264baf6d44394b13d8c6f6cec1cb7565be3739748c90cb76246d977ae55ba0\n  Stored in directory: /root/.cache/pip/wheels/df/59/6b/d4d1e0bcba957ab4e84e80d1f8dcf528d5074a5561b6d13e00\n  Building wheel for ml_collections (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94507 sha256=a23d539b9add814fd03fd07b6f112e91bbc82aa012be8c603b23391b7dd5e81c\n  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\nSuccessfully built jaxline ml_collections\nInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, gast, dill, contextlib2, absl-py, ml_collections, keras-preprocessing, jmp, google-auth-oauthlib, dm-haiku, tensorflow_datasets, tensorboard, chex, tensorflow, optax, jaxline\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.5.26\n    Uninstalling flatbuffers-23.5.26:\n      Successfully uninstalled flatbuffers-23.5.26\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorflow_datasets\n    Found existing installation: tensorflow-datasets 4.9.4\n    Uninstalling tensorflow-datasets-4.9.4:\n      Successfully uninstalled tensorflow-datasets-4.9.4\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: chex\n    Found existing installation: chex 0.1.85\n    Uninstalling chex-0.1.85:\n      Successfully uninstalled chex-0.1.85\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n  Attempting uninstall: optax\n    Found existing installation: optax 0.2.1\n    Uninstalling optax-0.2.1:\n      Successfully uninstalled optax-0.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nalbumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.23.2 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\nfeaturetools 1.30.0 requires numpy>=1.25.0, but you have numpy 1.23.2 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.3.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nmultiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.5.1 which is incompatible.\nonnx 1.15.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.5.1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.2 which is incompatible.\npylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nrmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.9.1 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.9.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.1 which is incompatible.\ntensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.9.1 which is incompatible.\nwoodwork 0.29.0 requires numpy>=1.25.0, but you have numpy 1.23.2 which is incompatible.\nxarray 2024.2.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed absl-py-1.2.0 chex-0.1.7 contextlib2-21.6.0 dill-0.3.5.1 dm-haiku-0.0.7 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 jaxline-0.0.5 jmp-0.0.4 keras-2.9.0 keras-preprocessing-1.1.2 ml_collections-0.1.1 numpy-1.23.2 optax-0.1.3 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow_datasets-4.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall -y jax\n!pip install jax==0.4.13\n\n!pip uninstall -y jaxlib\n!pip install jaxlib==0.4.13\n\n!pip uninstall -y dm-haiku\n!pip install dm-haiku==0.0.9","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:12:04.609657Z","iopub.execute_input":"2024-04-07T11:12:04.610509Z","iopub.status.idle":"2024-04-07T11:13:12.978305Z","shell.execute_reply.started":"2024-04-07T11:12:04.610465Z","shell.execute_reply":"2024-04-07T11:13:12.977129Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found existing installation: jax 0.4.23\nUninstalling jax-0.4.23:\n  Successfully uninstalled jax-0.4.23\nCollecting jax==0.4.13\n  Downloading jax-0.4.13.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (0.2.0)\nRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (1.23.2)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (3.3.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.13) (1.11.4)\nBuilding wheels for collected packages: jax\n  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518704 sha256=095d652fa636a60f874b400523c75948450ebd6adc10dd01a8962efaf1db2ee7\n  Stored in directory: /root/.cache/pip/wheels/f3/7a/25/f297f69029b5e4064e4736a0c4b3996a44cc27781c120bcb99\nSuccessfully built jax\nInstalling collected packages: jax\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflax 0.8.2 requires jax>=0.4.19, but you have jax 0.4.13 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed jax-0.4.13\nFound existing installation: jaxlib 0.4.23.dev20240116\nUninstalling jaxlib-0.4.23.dev20240116:\n  Successfully uninstalled jaxlib-0.4.23.dev20240116\nCollecting jaxlib==0.4.13\n  Downloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (1.11.4)\nRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (1.23.2)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jaxlib==0.4.13) (0.2.0)\nDownloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl (71.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: jaxlib\nSuccessfully installed jaxlib-0.4.13\nFound existing installation: dm-haiku 0.0.7\nUninstalling dm-haiku-0.0.7:\n  Successfully uninstalled dm-haiku-0.0.7\nCollecting dm-haiku==0.0.9\n  Downloading dm_haiku-0.0.9-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: absl-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.9) (1.2.0)\nRequirement already satisfied: jmp>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.9) (0.0.4)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.9) (1.23.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from dm-haiku==0.0.9) (0.9.0)\nDownloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: dm-haiku\nSuccessfully installed dm-haiku-0.0.9\n","output_type":"stream"}]},{"cell_type":"code","source":"# 配置地址\nPATH_TO_CONFIG = './emergent_in_context_learning/experiment/configs/images_all_exemplars.py'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 检查点地址\n./emergent_in_context_learning/models/latest/step_781_2024-04-07T14:37:38/checkpoint.dill","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:13:12.979892Z","iopub.execute_input":"2024-04-07T11:13:12.980244Z","iopub.status.idle":"2024-04-07T11:13:14.007797Z","shell.execute_reply.started":"2024-04-07T11:13:12.980211Z","shell.execute_reply":"2024-04-07T11:13:14.006426Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"上下文：[Step 781] eval_loss=7.63, eval_accuracy=0.00","metadata":{}},{"cell_type":"code","source":"python -m emergent_in_context_learning.experiment.experiment --config ./emergent_in_context_learning/experiment/configs/images_all_exemplars.py --logtostderr --config.one_off_evaluate --config.restore_path ./emergent_in_context_learning/models/latest/step_781_2024-04-07T14:37:38/ --jaxline_mode eval_fewshot_holdout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"权重：[Step 781] eval_loss=7.63, eval_accuracy=0.00","metadata":{}},{"cell_type":"code","source":"python -m emergent_in_context_learning.experiment.experiment --config ./emergent_in_context_learning/experiment/configs/images_all_exemplars.py --logtostderr --config.one_off_evaluate --config.restore_path ./emergent_in_context_learning/models/latest/step_781_2024-04-07T14:37:38/ --jaxline_mode eval_no_support_zipfian","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_TO_CONFIG = 'emergent_in_context_learning/experiment/configs/images_all_exemplars.py'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:13:14.009241Z","iopub.execute_input":"2024-04-07T11:13:14.009514Z","iopub.status.idle":"2024-04-07T11:13:14.014551Z","shell.execute_reply.started":"2024-04-07T11:13:14.009488Z","shell.execute_reply":"2024-04-07T11:13:14.013627Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!python -m emergent_in_context_learning.experiment.experiment --config $PATH_TO_CONFIG --jaxline_mode train --logtostderr\n# (save checkpoints using Ctrl+C)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:13:14.015976Z","iopub.execute_input":"2024-04-07T11:13:14.016899Z","iopub.status.idle":"2024-04-07T11:13:22.330129Z","shell.execute_reply.started":"2024-04-07T11:13:14.016869Z","shell.execute_reply":"2024-04-07T11:13:22.329098Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 762, in <module>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 762, in <lambda>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 736, in main\n    experiment_instance = experiment_class()\nTypeError: Experiment.__init__() missing 3 required positional arguments: 'mode', 'init_rng', and 'config'\n","output_type":"stream"}]},{"cell_type":"code","source":"CKPT_DIR = '/kaggle/working/models'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:13:22.331814Z","iopub.execute_input":"2024-04-07T11:13:22.332188Z","iopub.status.idle":"2024-04-07T11:13:22.337865Z","shell.execute_reply.started":"2024-04-07T11:13:22.332156Z","shell.execute_reply":"2024-04-07T11:13:22.336654Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!python -m emergent_in_context_learning.experiment.experiment --config $PATH_TO_CONFIG --logtostderr --config.one_off_evaluate --config.restore_path $CKPT_DIR --jaxline_mode eval_no_support_zipfian","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:13:22.339454Z","iopub.execute_input":"2024-04-07T11:13:22.339869Z","iopub.status.idle":"2024-04-07T11:13:28.778613Z","shell.execute_reply.started":"2024-04-07T11:13:22.339828Z","shell.execute_reply":"2024-04-07T11:13:28.777350Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 762, in <module>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 762, in <lambda>\n    app.run(lambda argv: main(argv, Experiment))\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 726, in main\n    _restore_state_to_in_memory_checkpointer(restore_path)\n  File \"/kaggle/working/emergent_in_context_learning/experiment/experiment.py\", line 639, in _restore_state_to_in_memory_checkpointer\n    with open(python_state_path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/models/checkpoint.dill'\n","output_type":"stream"}]}]}